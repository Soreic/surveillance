%% need no \usepackage{Sweave.sty}
<<setup,cache=FALSE,include=FALSE>>=
source("setup.R")
@


\subsection[twinstim]{\code{twinstim}} \label{sec:models:twinstim}


  \begin{itemize}
  \item Permutation test to evaluate importance of epidemic component
    
  \item variables are allowed to appear in both components.
    no issues with coefficient correlation
    
  \end{itemize}

  
  
  
\subsubsection{On the reproduction number} \label{twinstim:R0}


The point process model \eqref{eqn:twinstim} features a
reproduction number derived from its branching process interpretation.
New infections may either originate from the endemic component representing
immigration independent of the history of the epidemic, or they are triggered by
some previously infected individual via the epidemic component. As soon as an
individual becomes infected, it spreads the disease
according to an inhomogeneous Poisson process with rate 
$\eta_j \cdot g(t-t_j)\cdot f(\norm{\bm{s}-\bm{s_j}})$ around its origin.
Since this process is independent of the individuals parentage and of other
infections, 
\begin{equation*}
  \mu_j = \eta_j \cdot
  \left[ \int_0^{T-t_j} g(t) \,dt \right] \cdot
  \left[ \int_{\bm{W}-\bm{s_j}} f(\bm{s}) \,d\bm{s} \right]
\end{equation*}
is the expected number of secondary infections triggered by an infective $j$
during the remaining observation period $[t_j,T]$ in the observation region
$\bm{W}$. 
Thus, infectives with $\mu_j < 1$ are expected to cause less than one secondary
infection.

An interesting insight provides a comparison with the basic reproduction number
obtained from the simple SIR (susceptible-infected-recovered) compartmental model
for a closed population without demographics \citep{kermack.mckendrick1927}
represented by a system of ordinary differential equations:
\begin{align*}
  \frac{dS}{dt} &= -\beta S I 
  & \frac{dI}{dt} &= \beta S I - \gamma I 
  & \frac{dR}{dt} &= \gamma I
\end{align*}
Here, $N=S(t) + I(t) + R(t)$ is the (constant) population size, $\beta$ is the
transmission rate given contact between a susceptible and an infectious
individual, 
and $\gamma$ is the recovery rate ($1/\gamma$ is the average infectious period).
For this model, the basic reproduction number, i.e.\ the average number of
secondary cases arising from a single infective put into an entirely susceptible
population, is $R_0 = N \beta / \gamma$
\citep[see, e.g.,][Section 2.1]{Keeling.Rohani2008}.
A similar, but spatio-temporal epidemic model can be established from the point
process model \eqref{eqn:twinstim} with the following settings:
no endemic component,
homogeneous individuals ($\eta_j \equiv \beta$),
homogeneous mixing in space ($f(\bm{s}) \equiv 1$),
and exponential decay of infectivity ($g(t) = e^{-\alpha t}$).
Then, for $T \rightarrow \infty$,
\begin{equation*}
  \mu = \beta \cdot
  \left[ \int_0^\infty e^{-\alpha t} \,dt \right] \cdot
  \left[ \int_{\bm{W}-\bm{s_j}} 1 \,d\bm{s} \right] =
  \beta \cdot \abs{\bm{W}} / \alpha \:,
\end{equation*}
which corresponds to the above basic reproduction number interpreting
$\abs{\bm{W}}$ as the population size, $\beta$ as the transmission rate and
$\alpha$ as the removal rate.
Like in classic epidemic models, the process is sub-critical if $\mu < 1$ holds,
which means that its eventual extinction is almost sure. However, in the full
point process model \eqref{eqn:twinstim} with an endemic component, new
infections may always occur via ``immigration''. Hence, the reproduction number
as estimated from this model is adjusted for such new infections occurring
independently of previous infections. It therefore tends to be lower than the
one estimated from a classical non-spatial SIR model without immigration of
infectives.




\section{Computational issues with the spatial kernel}



\subsection{Numerical integration}
\label{twinstim:polyCub}

Evaluation of both the log-likelihood and the score function involves solution
of the spatial integrals
\[
\iint_{\bm{W}-\bm{s}_j} f_{2D}(\bm{s}) \,d\bm{s} =
\iint_{\bm{W}-\bm{s}_j} f(\norm{\bm{s}}) \,d\bm{s}
\]
of the interaction kernel over translated versions of the observation region
$\bm{W}$ with origin at the events' locations.
The score function
further requires the integral of the partial derivatives
$\frac{\partial f(\norm{\bm{s}})}{\partial \tilde{\sigma}}$ and
$\frac{\partial f(\norm{\bm{s}})}{\partial \tilde{d}}$ over these polygonal
domains.
The spatial integrations are only trivial for constant $f$ but otherwise
require some cubature method.

For the previously used Gaussian kernel, the two-dimensional midpoint rule was
found to be best suited if combined with an adaptive choice of the bandwidth
depending on the (current) value of the kernel's standard deviation $\sigma$.
However, this is not appropriate for the power law kernel, which results in
rather ``spiky hills'' to integrate and which would require a very small
bandwidth (high number of cubature nodes) to obtain enough accuracy.
Furthermore, a trick was used for the Gaussian kernel, in case a
$6\sigma$ (i.e., very high quantile) circle around $\bm{s}_j$ lay completely
inside $\bm{W}$. Then, the spatial integral was approximated by the integral
over this circular domain only, which is available analytically for the
Gaussian density via the $\chi^2$ distribution
\citep[Formula 26.3.24]{Abramowitz.Stegun1972}.
Although analytical integration
over circular domains is also possible for the power-law kernels (see
Appendix \ref{appendix:twinstim:Fcircle}),
it is not directly applicable since power
laws feature a heavy tail and thus very large quantiles such that a 99.9\%
circle would rarely fall completely inside $\bm{W}$. This trick was only used to
get initial parameter estimates by truncating the spatial interaction function
at 200 km (runtime ??? minutes, compared to
??? seconds for the previous model with
Gaussian $f$), but for the 
final model integration over the whole of $\bm{W}$ has to be performed for all
observations (runtime ??? minutes)
to capture occasional long-range transmissions
enabled by the power law. Therefore, a more sophisticated cubature method is
needed.

\citet{sommariva.vianello2007} proposed a cubature rule over
polygonal domains which is exact for all bivariate polynomials up to a
degree $2n-1$. The number of required cubature nodes depends on the specific
shape of the polygon, but is bounded above by $Ln(n+1)$ with $L$ being the
number of vertices. Their cubature rule actually incorporates appropriately
transformed weights and nodes of one-dimensional Gauss-Legendre quadrature
in both dimensions (with $n$ and $n+1$ nodes, respectively),
thus the name ``product Gauss cubature''. 
%Let $\Pi$ denote an arbitrary polygon with vertices $V_1,\dots,V_L$ (and $V_{L+1} := V_1$).
The method is briefly illustrated in \citet[Section 3.2.5]{meyer2009}
and available either in its original \proglang{MATLAB} implementation by
\citet{sommariva.vianello2007:code}
or as an \proglang{R} port in package \pkg{polyCub} \citep{R:polyCub}.

Benchmark experiments of the product Gauss cubature are conducted for both
$f_{2D}(\bm{s})$ and its partial derivatives prior to optimisation to 
determine the required number of cubature nodes.
For the Lomax kernel, $n=40$ has been used for all three functions, whereas
$n=60$ was necessary for the lagged power law.
The cubature method additionally
requires the setting of a ``baseline'' in the first dimension, which was chosen
as the abscissa of the absolute maximum of the respective function $f(x)$,
$\frac{\partial f(x)}{\partial \tilde{\sigma}}$ or
$\frac{\partial f(x)}{\partial \tilde{d}}$ to have more nodes in that region.
%% An additional coordinate rotation proposed by \citet{sommariva.vianello2007}
%% would guarantee that all nodes fall inside the polygon at least for convex
%% polygons; however, this is no requirement for the integrands in question and in
%% our setting the potential gain in precision was small and did not justify
%% increased computational cost. \marginnote{clarify}
Convergence of the log-likelihood
optimisation can finally be verified by rerunning optimisation with a higher
number of nodes using the estimates from the previous fit as initial values.







\subsection{Numerical integration over circular domains}
\label{twinstim:Fcircle}


The integration of the isotropic ``hill'' $f_{2D}(\bm{s})$ over a circular
domain can be solved by cutting the hill into circular
slices from the bottom to the top and integrating the area of these slices along
the height, i.e.
\[
\int_{b(\bm{0},r)} f_{2D}(\bm{s}) \,d\bm{s} = \pi r^2 f(r) + \int_{f(r)}^{f(0)}
\pi [f^{-1}(z)]^2 \,dz 
\]
The first term corresponds to the basement plateau of radius $r$ and height
$f(r)$, whereas the integrand of the second term corresponds to the area of the
circular slice at height $z$.
Note that $f^{-1}$ exists since $f$ is strictly decreasing, for instance the
Lomax kernel \eqref{eqn:siaf.powerlaw} has the inverse
$f^{-1}(z) = z^{-\frac{1}{d}} - \sigma$ for $z > 0$.
Simple calculus yields
\[
\int \left(f^{-1}(z)\right)^2 \,dz =
\begin{cases}
  \log(z) - 4 \sigma \sqrt{z} + \sigma^2 z & \text{, if } d = 2,\\
  -z^{-1} - 2 \sigma \log(z) + \sigma^2 z & \text{, if } d = 1,\\
z^{\frac{d-2}{d}} \frac{d}{d-2} -
2 \sigma z^{\frac{d-1}{d}} \frac{d}{d-1} + \sigma^2 z & \text{, otherwise.}
\end{cases}
\]

A similar formula can also be derived for the lagged power law
\eqref{eqn:siaf.powerlawL}. For $r < \sigma$, integration is trivial since the
integrand is just constantly 1 in this domain; otherwise, integration works as
above via the inverse of the power-law part $f_L^{-1}(z) = \sigma z^{-\frac{1}{d}}$
for $z \in (0;1]$ and
\[
\int_{f(r)}^{f(0)} \left(f_L^{-1}(z)\right)^2 \,dz =
\sigma^2 \int_{f(r)}^1 z^{-\frac{2}{d}} \,dz = 
\sigma^2 \cdot \begin{cases}
  -d \log\left( \frac{\sigma}{r} \right) & \text{, if } d = 2,\\
  \frac{d}{d-2} \left[ 1 - \left(\frac{\sigma}{r}\right)^{d-2} \right] & \text{, otherwise.}
\end{cases}
\]




\subsection{Simulation}
\label{twinstim:simulation}

To simulate epidemics from (fitted) \code{twinstim}'s, an
algorithm which returns random points drawn proportional to the spatial
interaction function $f_{2D}(\bm{s})$ is additionally required.
In this specific case, it is convenient to switch to polar coordinates
$(r,\theta)$, which have a density proportional to
$r \cdot f_{2D}((r \cos(\theta), r \sin(\theta))^\top) = r \cdot f(r)$ (independent
of the angle $\theta$ since it is an isotropic kernel). The angle is drawn
uniformly in $[0,2\pi)$ and $r$ can be sampled by the inversion method with
two pitfalls: firstly, the density is improper on $\IR_0^+$ for $d \le 2$
but we only need to sample in the truncated domain $[0,\delta]$, and secondly,
the quantile function is not accessible in closed form such that numeric root
finding is used.
